def call_openrouter(messages, model="gpt-4o-mini"):
    """Robust OpenRouter API call with retry, fallback models, success logging, and Supabase tracking."""
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "HTTP-Referer": "https://legal-smegal-api-final.onrender.com",
        "Content-Type": "application/json",
    }

    # Model order: primary + fallback models
    model_chain = [model, "gpt-4o", "mistral-nemo:latest"]

    data = {
        "messages": messages,
        "temperature": 0.4,
        "max_tokens": 700,
    }

    def log_to_supabase(status, model_name, attempts, message):
        """Save model call results to Supabase 'ai_logs' table."""
        try:
            supabase.table("ai_logs").insert({
                "id": str(uuid.uuid4()),
                "model": model_name,
                "status": status,
                "attempts": attempts,
                "message": message[:500],  # limit length to avoid overflow
            }).execute()
            print(f"üìù Logged {status} for {model_name} after {attempts} attempts.")
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to log to Supabase: {e}")

    for current_model in model_chain:
        data["model"] = current_model
        for attempt in range(3):  # up to 3 retries per model
            try:
                print(f"üîπ Trying model {current_model} (attempt {attempt+1})...")
                resp = requests.post(
                    "https://openrouter.ai/api/v1/chat/completions",
                    headers=headers, json=data, timeout=60
                )

                # --- Successful response ---
                if resp.status_code == 200:
                    j = resp.json()
                    content = (
                        j.get("choices", [{}])[0]
                        .get("message", {})
                        .get("content", "")
                        .strip()
                    )
                    if content:
                        print(f"‚úÖ Response successfully generated by {current_model}")
                        log_to_supabase("success", current_model, attempt + 1, "Response OK")
                        return content

                # --- Retry on overload ---
                elif resp.status_code == 503:
                    print(f"‚ö†Ô∏è {current_model} overloaded (503). Retrying after delay...")
                    time.sleep(2 ** attempt)
                    continue

                # --- Unexpected status code ---
                else:
                    error_msg = f"HTTP {resp.status_code}: {resp.text[:200]}"
                    print(f"‚ùå {current_model} returned {error_msg}")
                    log_to_supabase("error", current_model, attempt + 1, error_msg)
                    break

            except requests.Timeout:
                print(f"‚è± Timeout from {current_model}, retrying after delay...")
                time.sleep(2 ** attempt)
                continue

            except Exception as e:
                print(f"‚ö†Ô∏è Unexpected error with {current_model}: {e}")
                log_to_supabase("error", current_model, attempt + 1, str(e))
                break

        print(f"‚ùå All retries failed for {current_model}, moving to next model...")

    # --- Fallback if all models fail ---
    fallback_error = {
        "error": {
            "code": 503,
            "message": "All AI models are currently overloaded. Please retry shortly.",
            "source": "openrouter",
            "status": "unavailable",
        }
    }
    print("üö® All models failed. Returning fallback JSON.")
    log_to_supabase("failed_all", "all_models", 3, "All models overloaded or unavailable")
    return json.dumps(fallback_error)
